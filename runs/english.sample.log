------
FLAGS
------
train-file: data/english.sample.train
test-file: data/english.sample.test
model-name: runs/english.sample.model
output-file: null
train: true
test: true
iters: 10
label: true
max-sent: -1
C: 0.01
label-loss-type: 0
gamma: 0.3 0.3
R: 50
word-vector:null
projective: false
pruning: false
hill-climbing converge (train): 300
hill-climbing converge (test): 100
thread: 4
file format: CONLL-X
feature hash bits: 20

use consecutive siblings: true
use grandparent: true
use head bigram: true
use grand siblings: true
use tri-siblings: true
use great-grandparent: false
use parent-sibling-child: false
use high-order: false
model: Standard
------

Warning: couldn't find coarse POS map for this language
Creating dictionaries ... 
Filtered DEPLABEL (32-->30)
4 8
Lexical items: 667 (10 bits)
Tag/label items: 80 (7 bits)  30 (5 bits)
Flag Bits: 9
Creation took [115 ms]
Creating Alphabet ... [126 ms]
Hash collision: 7.5408% (12635 / 167556)
Num of CONLL fine POS tags: 38
Num of CONLL coarse POS tags: 38
Num of labels: 30
Num of Syntactic Features: 3469 1048575
Creating instances ... 32 [20 ms]
=============================================
 Pre-training:
=============================================
Running MIRA ... 

  Iter 1	loss=1234.6915	uas=0.0539	[0s]

Init tensor ... 
  Unfolding matrix: 31230 / (3469*52035)  0.02% entries.
  Rank: 50 (max:50)  Sigma: max=0.293648 cut=0.032940

 |U|^2: 50.000000 min: -0.917001	max: 0.670396
 |V|^2: 50.000000 min: -0.989925	max: 0.972299
 |W|^2: 0.207655 min: -0.253206	max: 0.119396

Pre-training took 28993 ms.
=============================================

=============================================
 Training:
=============================================
Running MIRA ... 

  Iter 1	loss=1249.6857	uas=0.0591	[14s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.643478	LAS=0.391304	CAS=0.000000	[3.58s]

_____________________________________________


  Iter 2	loss=614.9117	uas=0.3171	[10s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.660870	LAS=0.526087	CAS=0.000000	[2.53s]

_____________________________________________


  Iter 3	loss=339.7528	uas=0.5058	[12s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.691304	LAS=0.565217	CAS=0.000000	[2.52s]

_____________________________________________


  Iter 4	loss=204.0249	uas=0.6329	[13s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.695652	LAS=0.565217	CAS=0.000000	[2.40s]

_____________________________________________


  Iter 5	loss=119.0326	uas=0.7304	[15s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.695652	LAS=0.573913	CAS=0.000000	[2.52s]

_____________________________________________


  Iter 6	loss=68.9312	uas=0.7535	[12s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.704348	LAS=0.586957	CAS=0.090909	[2.51s]

_____________________________________________


  Iter 7	loss=41.9057	uas=0.8164	[14s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.595652	CAS=0.090909	[2.75s]

_____________________________________________


  Iter 8	loss=24.9748	uas=0.8203	[14s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.595652	CAS=0.090909	[2.72s]

_____________________________________________


  Iter 9	loss=16.3521	uas=0.8421	[14s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.595652	CAS=0.090909	[2.51s]

_____________________________________________


  Iter 10	loss=7.6625	uas=0.8383	[14s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.595652	CAS=0.090909	[2.63s]

_____________________________________________


Training took 165675 ms.
=============================================

 Evaluating: data/english.sample.test
  Tokens: 230
  Sentences: 11
  UAS=0.700000	LAS=0.591304	CAS=0.090909	[1.33s]
