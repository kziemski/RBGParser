------
FLAGS
------
train-file: data/english.sample.train
test-file: data/english.sample.test
model-name: runs/english.sample.model
output-file: null
train: true
test: true
iters: 10
label: true
max-sent: -1
C: 0.01
label-loss-type: 0
gamma: 0.3 1.0
R: 50
word-vector:null
projective: false
pruning: false
hill-climbing converge (train): 300
hill-climbing converge (test): 100
thread: 4
file format: CONLL-X
feature hash bits: 20

use consecutive siblings: true
use grandparent: true
use head bigram: true
use grand siblings: true
use tri-siblings: true
use great-grandparent: false
use parent-sibling-child: false
use high-order: false
model: Standard
------

Warning: couldn't find coarse POS map for this language
Creating dictionaries ... 
Filtered DEPLABEL (32-->30)
4 8
Lexical items: 667 (10 bits)
Tag/label items: 80 (7 bits)  30 (5 bits)
Flag Bits: 9
Creation took [203 ms]
Creating Alphabet ... [146 ms]
Hash collision: 7.5408% (12635 / 167556)
Num of CONLL fine POS tags: 38
Num of CONLL coarse POS tags: 38
Num of labels: 30
Num of Syntactic Features: 3469 1048575
Creating instances ... 32 [23 ms]
=============================================
 Pre-training:
=============================================
Running MIRA ... 

  Iter 1	loss=1234.6915	uas=0.0539	[0s]

Init tensor ... 
  Unfolding matrix: 31230 / (3469*52035)  0.02% entries.
  Rank: 50 (max:50)  Sigma: max=0.293648 cut=0.032940

 |U|^2: 50.000000 min: -0.917001	max: 0.670396
 |V|^2: 50.000000 min: -0.989925	max: 0.972299
 |W|^2: 0.207655 min: -0.253206	max: 0.119396

Pre-training took 5575 ms.
=============================================

=============================================
 Training:
=============================================
Running MIRA ... 

  Iter 1	loss=1175.4676	uas=0.0513	[16s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.639130	LAS=0.513043	CAS=0.000000	[4.54s]

_____________________________________________


  Iter 2	loss=475.8616	uas=0.3261	[17s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.656522	LAS=0.539130	CAS=0.000000	[2.84s]

_____________________________________________


  Iter 3	loss=221.0069	uas=0.5109	[13s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.565217	CAS=0.000000	[2.81s]

_____________________________________________


  Iter 4	loss=108.0036	uas=0.6457	[16s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.686957	LAS=0.578261	CAS=0.090909	[2.59s]

_____________________________________________


  Iter 5	loss=59.0476	uas=0.7266	[16s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.700000	LAS=0.595652	CAS=0.090909	[2.89s]

_____________________________________________


  Iter 6	loss=31.7596	uas=0.7779	[19s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.700000	LAS=0.591304	CAS=0.090909	[2.84s]

_____________________________________________


  Iter 7	loss=18.5601	uas=0.7728	[17s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.704348	LAS=0.595652	CAS=0.090909	[2.61s]

_____________________________________________


  Iter 8	loss=11.8340	uas=0.8023	[16s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.704348	LAS=0.595652	CAS=0.090909	[2.62s]

_____________________________________________


  Iter 9	loss=6.4282	uas=0.8036	[17s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.600000	CAS=0.090909	[2.85s]

_____________________________________________


  Iter 10	loss=2.4961	uas=0.8100	[16s]

_____________________________________________

 Evaluation: data/english.sample.test

  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.600000	CAS=0.090909	[2.73s]

_____________________________________________


Training took 198803 ms.
=============================================

 Evaluating: data/english.sample.test
  Tokens: 230
  Sentences: 11
  UAS=0.708696	LAS=0.600000	CAS=0.090909	[1.38s]
