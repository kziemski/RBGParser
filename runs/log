Warning: couldn't find coarse POS map for this language
Creating dictionaries ... 
Filtered DEPLABEL (32-->30)
4 8
Lexical items: 667 (10 bits)
Tag/label items: 80 (7 bits)  30 (5 bits)
Flag Bits: 4
Creation took [102 ms]
Creating Alphabet ... [81 ms]
Hash collision: 12.5617% (9061 / 72132)
Num of CONLL fine POS tags: 38
Num of CONLL coarse POS tags: 38
Num of labels: 30
Num of Syntactic Features: 3469 262143
Creating instances ... 32 [20 ms]
=============================================
 Training Pruner:
=============================================
Running MIRA ... 
  Iter 1	loss=685.9544	uas=0.0205	[0s]
  Iter 2	loss=291.5053	uas=0.1425	[0s]
  Iter 3	loss=117.6416	uas=0.2965	[0s]
  Iter 4	loss=45.6625	uas=0.4570	[0s]
  Iter 5	loss=19.2642	uas=0.5481	[0s]
  Iter 6	loss=9.5223	uas=0.6175	[0s]
  Iter 7	loss=4.7895	uas=0.6932	[0s]
  Iter 8	loss=2.4363	uas=0.7291	[0s]
  Iter 9	loss=1.3445	uas=0.7779	[0s]
  Iter 10	loss=0.7153	uas=0.8139	[0s]

Training took 1668 ms.
=============================================

------
FLAGS
------
train-file: data/english.sample.train.lab
test-file: data/english.sample.test.lab
model-name: runs/english.sample.model
output-file: null
train: true
test: true
iters: 10
label: false
max-sent: -1
C: 0.01
label-loss-type: 0
gamma: 0.3 1.0
R: 50
word-vector:null
projective: false
pruning: true
hill-climbing converge (train): 300
hill-climbing converge (test): 100
thread: 4
file format: CONLL-X
feature hash bits: 20

use consecutive siblings: false
use grandparent: true
use head bigram: false
use grand siblings: false
use tri-siblings: false
use great-grandparent: false
use parent-sibling-child: false
use high-order: false
model: Second
------

Warning: couldn't find coarse POS map for this language
Creating dictionaries ... 
Filtered DEPLABEL (32-->30)
4 8
Lexical items: 667 (10 bits)
Tag/label items: 80 (7 bits)  30 (5 bits)
Flag Bits: 4
Creation took [16 ms]
Creating Alphabet ... [33 ms]
Hash collision: 6.1275% (8159 / 133154)
Num of CONLL fine POS tags: 38
Num of CONLL coarse POS tags: 38
Num of labels: 30
Num of Syntactic Features: 3469 1048575
Creating instances ... 32 [6 ms]
=============================================
 Training:
=============================================
Running MIRA ... 

  Iter 1	loss=723.7437	uas=0.0064	[6s]
 |U|^2: 50.034896 min: -0.033230	max: 0.036191
 |V|^2: 50.034607 min: -0.038849	max: 0.046685
 |W|^2: 50.007236 min: -0.500033	max: 0.498945
 |U2|^2: 499.910475 min: -0.094949	max: 0.095058
 |V2|^2: 499.911154 min: -0.095505	max: 0.094464
 |W2|^2: 49.898771 min: -0.526945	max: 0.534959
 |X2|^2: 499.909773 min: -0.094553	max: 0.095023
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.608696	LAS=0.000000	CAS=0.000000	[1.47s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 2	loss=411.7892	uas=0.1297	[6s]
 |U|^2: 50.142285 min: -0.041770	max: 0.046729
 |V|^2: 50.140880 min: -0.054400	max: 0.074367
 |W|^2: 50.090094 min: -0.499950	max: 0.499067
 |U2|^2: 499.898127 min: -0.095722	max: 0.095055
 |V2|^2: 499.899807 min: -0.096981	max: 0.095966
 |W2|^2: 49.877464 min: -0.527290	max: 0.535029
 |X2|^2: 499.897660 min: -0.095308	max: 0.100474
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.639130	LAS=0.000000	CAS=0.000000	[1.41s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 3	loss=210.9385	uas=0.3261	[6s]
 |U|^2: 50.228340 min: -0.045512	max: 0.053729
 |V|^2: 50.225948 min: -0.062004	max: 0.084479
 |W|^2: 50.163641 min: -0.499962	max: 0.499313
 |U2|^2: 499.922912 min: -0.098517	max: 0.096104
 |V2|^2: 499.925351 min: -0.098298	max: 0.096868
 |W2|^2: 49.897887 min: -0.527531	max: 0.535202
 |X2|^2: 499.922786 min: -0.096439	max: 0.100508
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.652174	LAS=0.000000	CAS=0.000000	[1.50s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 4	loss=103.4309	uas=0.4660	[8s]
 |U|^2: 50.286037 min: -0.049116	max: 0.058773
 |V|^2: 50.283195 min: -0.066470	max: 0.088047
 |W|^2: 50.216334 min: -0.500007	max: 0.499433
 |U2|^2: 499.931337 min: -0.099051	max: 0.096349
 |V2|^2: 499.933959 min: -0.098418	max: 0.097485
 |W2|^2: 49.904702 min: -0.527212	max: 0.535335
 |X2|^2: 499.931366 min: -0.096864	max: 0.104894
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.647826	LAS=0.000000	CAS=0.000000	[1.45s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 5	loss=51.7029	uas=0.5995	[8s]
 |U|^2: 50.318925 min: -0.049823	max: 0.060518
 |V|^2: 50.315837 min: -0.068770	max: 0.091562
 |W|^2: 50.247313 min: -0.500000	max: 0.499499
 |U2|^2: 499.942029 min: -0.100742	max: 0.096402
 |V2|^2: 499.944722 min: -0.098723	max: 0.097485
 |W2|^2: 49.914809 min: -0.527384	max: 0.535404
 |X2|^2: 499.942105 min: -0.097057	max: 0.107159
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.652174	LAS=0.000000	CAS=0.000000	[1.45s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 6	loss=26.4776	uas=0.6483	[8s]
 |U|^2: 50.339546 min: -0.050756	max: 0.061223
 |V|^2: 50.336374 min: -0.071163	max: 0.093850
 |W|^2: 50.267279 min: -0.500017	max: 0.499585
 |U2|^2: 499.945849 min: -0.100388	max: 0.096498
 |V2|^2: 499.948554 min: -0.099064	max: 0.097676
 |W2|^2: 49.918431 min: -0.527502	max: 0.535451
 |X2|^2: 499.945931 min: -0.097596	max: 0.106080
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.652174	LAS=0.000000	CAS=0.000000	[1.42s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________

