Warning: couldn't find coarse POS map for this language
Creating dictionaries ... 
Filtered DEPLABEL (32-->30)
4 8
Lexical items: 667 (10 bits)
Tag/label items: 80 (7 bits)  30 (5 bits)
Flag Bits: 4
Creation took [149 ms]
Creating Alphabet ... [104 ms]
Hash collision: 12.5617% (9061 / 72132)
Num of CONLL fine POS tags: 38
Num of CONLL coarse POS tags: 38
Num of labels: 30
Num of Syntactic Features: 3469 262143
Creating instances ... 32 [19 ms]
=============================================
 Training Pruner:
=============================================
Running MIRA ... 
  Iter 1	loss=685.9544	uas=0.0205	[0s]
  Iter 2	loss=291.5053	uas=0.1425	[0s]
  Iter 3	loss=117.6416	uas=0.2965	[0s]
  Iter 4	loss=45.6625	uas=0.4570	[0s]
  Iter 5	loss=19.2642	uas=0.5481	[0s]
  Iter 6	loss=9.5223	uas=0.6175	[0s]
  Iter 7	loss=4.7895	uas=0.6932	[0s]
  Iter 8	loss=2.4363	uas=0.7291	[0s]
  Iter 9	loss=1.3445	uas=0.7779	[0s]
  Iter 10	loss=0.7153	uas=0.8139	[0s]

Training took 1692 ms.
=============================================

------
FLAGS
------
train-file: data/english.sample.train.lab
test-file: data/english.sample.test.lab
model-name: runs/english.sample.model
output-file: null
train: true
test: true
iters: 10
label: false
max-sent: -1
C: 0.01
label-loss-type: 0
gamma: 0.3 1.0
R: 50
word-vector:null
projective: false
pruning: true
hill-climbing converge (train): 300
hill-climbing converge (test): 100
thread: 4
file format: CONLL-X
feature hash bits: 20

use consecutive siblings: false
use grandparent: true
use head bigram: false
use grand siblings: false
use tri-siblings: false
use great-grandparent: false
use parent-sibling-child: false
use high-order: false
model: Second
------

Warning: couldn't find coarse POS map for this language
Creating dictionaries ... 
Filtered DEPLABEL (32-->30)
4 8
Lexical items: 667 (10 bits)
Tag/label items: 80 (7 bits)  30 (5 bits)
Flag Bits: 4
Creation took [16 ms]
Creating Alphabet ... [33 ms]
Hash collision: 6.1275% (8159 / 133154)
Num of CONLL fine POS tags: 38
Num of CONLL coarse POS tags: 38
Num of labels: 30
Num of Syntactic Features: 3469 1048575
Creating instances ... 32 [6 ms]
=============================================
 Training:
=============================================
Running MIRA ... 

  Iter 1	loss=724.4955	uas=0.0077	[7s]
 |U|^2: 575.847617 min: -0.101796	max: 0.103423
 |V|^2: 577.847076 min: -0.102277	max: 0.101795
 |W|^2: 2.368442 min: -0.104278	max: 0.098926
 |U2|^2: 577.757299 min: -0.100299	max: 0.100279
 |V2|^2: 577.763569 min: -0.100954	max: 0.100104
 |W2|^2: 2.522833 min: -0.099277	max: 0.100043
 |X2|^2: 577.407215 min: -0.100185	max: 0.100220
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.617391	LAS=0.000000	CAS=0.000000	[1.62s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 2	loss=417.0714	uas=0.1284	[6s]
 |U|^2: 575.910729 min: -0.105510	max: 0.102476
 |V|^2: 577.910272 min: -0.107270	max: 0.104380
 |W|^2: 2.431045 min: -0.120232	max: 0.108545
 |U2|^2: 577.759873 min: -0.101058	max: 0.100721
 |V2|^2: 577.766183 min: -0.101802	max: 0.100283
 |W2|^2: 2.525478 min: -0.099089	max: 0.101937
 |X2|^2: 577.409779 min: -0.100722	max: 0.100990
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.639130	LAS=0.000000	CAS=0.000000	[1.63s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 3	loss=213.1317	uas=0.3196	[6s]
 |U|^2: 575.970673 min: -0.108307	max: 0.104109
 |V|^2: 577.970200 min: -0.110657	max: 0.105445
 |W|^2: 2.490049 min: -0.136176	max: 0.110002
 |U2|^2: 577.763084 min: -0.102609	max: 0.101016
 |V2|^2: 577.769406 min: -0.102573	max: 0.100529
 |W2|^2: 2.528746 min: -0.099093	max: 0.103965
 |X2|^2: 577.412980 min: -0.101196	max: 0.101499
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.669565	LAS=0.000000	CAS=0.000000	[1.40s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 4	loss=100.0586	uas=0.4544	[7s]
 |U|^2: 576.020002 min: -0.109089	max: 0.105200
 |V|^2: 578.019442 min: -0.116884	max: 0.106155
 |W|^2: 2.538829 min: -0.152240	max: 0.113596
 |U2|^2: 577.766007 min: -0.103970	max: 0.101097
 |V2|^2: 577.772335 min: -0.102637	max: 0.100584
 |W2|^2: 2.531691 min: -0.099236	max: 0.105225
 |X2|^2: 577.415895 min: -0.101356	max: 0.101693
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[1.52s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 5	loss=53.0801	uas=0.6136	[7s]
 |U|^2: 576.048793 min: -0.110108	max: 0.106281
 |V|^2: 578.048203 min: -0.119671	max: 0.106471
 |W|^2: 2.567280 min: -0.158738	max: 0.118068
 |U2|^2: 577.768266 min: -0.104121	max: 0.101175
 |V2|^2: 577.774595 min: -0.103298	max: 0.100737
 |W2|^2: 2.533951 min: -0.099235	max: 0.106190
 |X2|^2: 577.418151 min: -0.101535	max: 0.101776
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[1.49s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 6	loss=27.7709	uas=0.6804	[8s]
 |U|^2: 576.066885 min: -0.110717	max: 0.106263
 |V|^2: 578.066264 min: -0.121916	max: 0.106732
 |W|^2: 2.585241 min: -0.163972	max: 0.119882
 |U2|^2: 577.768404 min: -0.104357	max: 0.101210
 |V2|^2: 577.774734 min: -0.103422	max: 0.100730
 |W2|^2: 2.534089 min: -0.099265	max: 0.106399
 |X2|^2: 577.418288 min: -0.101503	max: 0.101828
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[1.44s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 7	loss=16.7959	uas=0.7163	[7s]
 |U|^2: 576.076855 min: -0.111062	max: 0.106235
 |V|^2: 578.076203 min: -0.122833	max: 0.106897
 |W|^2: 2.595121 min: -0.165726	max: 0.121516
 |U2|^2: 577.769519 min: -0.104361	max: 0.101206
 |V2|^2: 577.775850 min: -0.103386	max: 0.100800
 |W2|^2: 2.535205 min: -0.099322	max: 0.106603
 |X2|^2: 577.419403 min: -0.101541	max: 0.101822
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.678261	LAS=0.000000	CAS=0.000000	[1.42s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 8	loss=9.4246	uas=0.7356	[7s]
 |U|^2: 576.083880 min: -0.111293	max: 0.106229
 |V|^2: 578.083229 min: -0.122216	max: 0.107072
 |W|^2: 2.602093 min: -0.165221	max: 0.122348
 |U2|^2: 577.769627 min: -0.104410	max: 0.101205
 |V2|^2: 577.775958 min: -0.103290	max: 0.100815
 |W2|^2: 2.535313 min: -0.099326	max: 0.106551
 |X2|^2: 577.419511 min: -0.101631	max: 0.101836
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[1.47s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 9	loss=4.4396	uas=0.7445	[7s]
 |U|^2: 576.087951 min: -0.111300	max: 0.106640
 |V|^2: 578.087295 min: -0.122212	max: 0.107055
 |W|^2: 2.606151 min: -0.166196	max: 0.122875
 |U2|^2: 577.769740 min: -0.104465	max: 0.101216
 |V2|^2: 577.776071 min: -0.103224	max: 0.100825
 |W2|^2: 2.535425 min: -0.099331	max: 0.106578
 |X2|^2: 577.419624 min: -0.101604	max: 0.101825
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[1.54s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


  Iter 10	loss=4.7014	uas=0.8049	[8s]
 |U|^2: 576.092032 min: -0.111403	max: 0.106764
 |V|^2: 578.091372 min: -0.122916	max: 0.107085
 |W|^2: 2.610219 min: -0.167418	max: 0.122656
 |U2|^2: 577.770044 min: -0.104466	max: 0.101221
 |V2|^2: 577.776375 min: -0.103230	max: 0.100840
 |W2|^2: 2.535730 min: -0.099347	max: 0.106633
 |X2|^2: 577.419928 min: -0.101606	max: 0.101841
  Pruning Recall: 1.0000	Effcy: 0.9587

_____________________________________________

 Evaluation: data/english.sample.test.lab

  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[1.51s]
  Pruning Recall: 1.0000	Effcy: 0.9907

_____________________________________________


Training took 91103 ms.
=============================================

 Evaluating: data/english.sample.test.lab
  Tokens: 230
  Sentences: 11
  UAS=0.673913	LAS=0.000000	CAS=0.000000	[0.71s]
  Pruning Recall: 1.0000	Effcy: 0.9907
